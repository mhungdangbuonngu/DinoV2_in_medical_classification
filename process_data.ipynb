{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and load data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entry = pd.read_csv(\"Data_Entry_2017.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                        0.143  0.143          NaN  \n",
       "1                        0.143  0.143          NaN  \n",
       "2                        0.168  0.168          NaN  \n",
       "3                        0.171  0.171          NaN  \n",
       "4                        0.143  0.143          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process folder\n",
    "Count how many images are there in each folder of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "root_path = \"G:\\\\Code\\\\Dataset\\\\archive\"\n",
    "\n",
    "img_folder = ['images_001', 'images_002', 'images_003', 'images_004', 'images_005', 'images_006', 'images_007', 'images_008', 'images_009', 'images_010', 'images_011', 'images_012']\n",
    "folder_size = {}\n",
    "\n",
    "print(exists(root_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in img_folder:\n",
    "\n",
    "    folder_size[folder] = (len(os.listdir((join(root_path, join(folder, \"images\"))))))\n",
    "\n",
    "print(folder_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels\n",
    "Get all labels and create a class to index mapping, then save to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "\n",
    "for labels in data_entry[\"Finding Labels\"].to_list()[1:]:\n",
    "    for label in labels.split(\"|\"):\n",
    "        label_map[label] = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for label in label_map:\n",
    "    label_map[label] = c\n",
    "    c += 1\n",
    "\n",
    "with open(\"label_map.json\", 'w') as f:\n",
    "    json.dump(label_map, f)\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-label image \n",
    "Assign each class with an index and then label each image with one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels_df = data_entry[[\"Image Index\",\"Finding Labels\"]]\n",
    "img_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear data entry since it's quite large, don't run if you didn't load it\n",
    "import gc\n",
    "\n",
    "del data_entry\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows , cols = img_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label to train folder\n",
    "train_label_path = join(root_path, \"train\\\\class_label\")\n",
    "for i in tqdm(range(rows - folder_size[\"images_012\"])):\n",
    "    if exists(join(train_label_path,img_name + \".npy\")): break\n",
    "    one_label = np.zeros(15)\n",
    "    label = img_labels_df.iloc[i,1] # row , col\n",
    "    for class_ in label.split('|'):\n",
    "        one_label[label_map[class_]] = 1\n",
    "\n",
    "    img_name = img_labels_df.iloc[i,0]\n",
    "    np.save(join(train_label_path,img_name), one_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label to test folder\n",
    "test_label_path = join(root_path, \"test\\\\class_label\")\n",
    "for i in tqdm(range(rows - folder_size[\"images_012\"], rows)):\n",
    "    if exists(join(test_label_path,img_name + \".npy\")): break\n",
    "    one_label = np.zeros(15)\n",
    "    label = img_labels_df.iloc[i,1] # row , col\n",
    "    for class_ in label.split('|'):\n",
    "        one_label[label_map[class_]] = 1\n",
    "\n",
    "    img_name = img_labels_df.iloc[i,0]\n",
    "    np.save(join(test_label_path,img_name), one_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process age, gender, VA\n",
    "Turn those categorical variables into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agv = data_entry[[\"Patient Age\",\"Patient Gender\",\"View Position\"]] \n",
    "agv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = np.mean(agv[\"Patient Age\"].to_numpy())\n",
    "std_ = np.std(agv[\"Patient Age\"].to_numpy())\n",
    "#normalize age\n",
    "agv[\"Patient Age\"] = pd.Series([(x-mean_)/std_ for x in agv[\"Patient Age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agv.loc[agv[\"Patient Gender\"] == \"M\", \"Patient Gender\"] = 0\n",
    "agv.loc[agv[\"Patient Gender\"] == \"F\", \"Patient Gender\"] = 1\n",
    "\n",
    "agv.loc[agv[\"View Position\"] == \"PA\", \"View Position\"] = 0\n",
    "agv.loc[agv[\"View Position\"] == \"AP\", \"View Position\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agv.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #add age, gender, VA to 384 features extracted from dinov2\n",
    "count = 0\n",
    "\n",
    "train_data_path = \"G:\\\\Code\\\\Dataset\\\\archive\\\\train\\\\img_feature\"\n",
    "test_data_path = \"G:\\\\Code\\\\Dataset\\\\archive\\\\test\\\\img_feature\"\n",
    "\n",
    "for folder in img_folder[:-1]:\n",
    "    for img_name in tqdm(os.listdir((join(root_path, join(folder, \"images\"))))):\n",
    "        row = agv.iloc[count,:].to_numpy()\n",
    "        tmp_npa = np.load(join(train_data_path, img_name + \".npy\"))\n",
    "        tmp_npa = np.append(tmp_npa,row).reshape((1,387))\n",
    "        np.save(join(train_data_path, img_name), tmp_npa)\n",
    "        count += 1\n",
    "\n",
    "for img_name in tqdm(os.listdir((join(root_path, join(img_folder[-1], \"images\"))))):\n",
    "    row = agv.iloc[count,:].to_numpy(dtype=np.float32)\n",
    "    tmp_npa = np.load(join(test_data_path, img_name + \".npy\"))   \n",
    "    tmp_npa = np.append(tmp_npa,row).reshape((1,387))\n",
    "    np.save(join(test_data_path, img_name), tmp_npa)\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove files \n",
    "Some classes have too many file that will make this dataset unbalanced,\n",
    "we need to remove them so it can be equivalent to some extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_map.json\", 'r') as label_file:\n",
    "\n",
    "    class_sample_count = json.load(label_file)\n",
    "\n",
    "for class_ in class_sample_count:\n",
    "    class_sample_count[class_] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104999/104999 [00:00<00:00, 1904142.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, labels in enumerate(tqdm(data_entry[\"Finding Labels\"][:104999])):\n",
    "    for label in labels.split('|'):\n",
    "        class_sample_count[label].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiomegaly: 2555\n",
      "Emphysema: 2272\n",
      "Effusion: 12340\n",
      "No Finding: 56720\n",
      "Hernia: 210\n",
      "Infiltration: 18538\n",
      "Mass: 5424\n",
      "Nodule: 5932\n",
      "Atelectasis: 10811\n",
      "Pneumothorax: 4776\n",
      "Pleural_Thickening: 3163\n",
      "Pneumonia: 1359\n",
      "Fibrosis: 1647\n",
      "Edema: 2209\n",
      "Consolidation: 4365\n"
     ]
    }
   ],
   "source": [
    "for class_ in class_sample_count:\n",
    "    print(f\"{class_}: {len(class_sample_count[class_])}\")\n",
    "\n",
    "#Effusion ,Infiltration, No Finding, Atelectasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2710)\n",
    "\n",
    "remove_files = {\n",
    "    \"No Finding\" : [],\n",
    "    \"Effusion\" : [],\n",
    "    \"Infiltration\" : [],\n",
    "    \"Atelectasis\" : []\n",
    "    }\n",
    "\n",
    "for class_ in remove_files:\n",
    "    class_size = len(class_sample_count[class_])\n",
    "    remove_files[class_] = random.sample(class_sample_count[class_], class_size - random.randint(4500,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Finding : 51961\n",
      "Effusion : 7422\n",
      "Infiltration : 13910\n",
      "Atelectasis : 5893\n"
     ]
    }
   ],
   "source": [
    "for class_ in remove_files:\n",
    "    print(f\"{class_} : {len(remove_files[class_])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75556"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_rm = set()\n",
    "\n",
    "for class_ in remove_files:\n",
    "    idx_to_rm.update(remove_files[class_])\n",
    "\n",
    "len(idx_to_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cardiomegaly': 950,\n",
       " 'Emphysema': 612,\n",
       " 'Effusion': 9000,\n",
       " 'No Finding': 51961,\n",
       " 'Hernia': 46,\n",
       " 'Infiltration': 14789,\n",
       " 'Mass': 1653,\n",
       " 'Nodule': 1715,\n",
       " 'Atelectasis': 7515,\n",
       " 'Pneumothorax': 1347,\n",
       " 'Pleural_Thickening': 1030,\n",
       " 'Pneumonia': 624,\n",
       " 'Fibrosis': 434,\n",
       " 'Edema': 974,\n",
       " 'Consolidation': 1791}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"label_map.json\", 'r') as label_file:\n",
    "\n",
    "    class_rm_count = json.load(label_file)\n",
    "\n",
    "for class_ in class_rm_count:\n",
    "    class_rm_count[class_] = 0\n",
    "\n",
    "for idx in idx_to_rm:\n",
    "    labels = data_entry.iloc[idx, 1]\n",
    "    for label in labels.split('|'):\n",
    "        class_rm_count[label] += 1\n",
    "    \n",
    "class_rm_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiomegaly: 1605\n",
      "Emphysema: 1660\n",
      "Effusion: 3340\n",
      "No Finding: 4759\n",
      "Hernia: 164\n",
      "Infiltration: 3749\n",
      "Mass: 3771\n",
      "Nodule: 4217\n",
      "Atelectasis: 3296\n",
      "Pneumothorax: 3429\n",
      "Pleural_Thickening: 2133\n",
      "Pneumonia: 735\n",
      "Fibrosis: 1213\n",
      "Edema: 1235\n",
      "Consolidation: 2574\n"
     ]
    }
   ],
   "source": [
    "for class_ in class_sample_count:\n",
    "    print(f\"{class_}: {len(class_sample_count[class_]) - class_rm_count[class_]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104999/104999 [01:16<00:00, 1370.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "old_train_path = \"G:/Code/Dataset/archive/train/class_label\"\n",
    "new_train_path = \"G:/Code/Dataset/archive/train_reduced/class_label\"\n",
    "\n",
    "for idx, file_name in enumerate(tqdm(data_entry[\"Image Index\"][:104999])):\n",
    "    if idx in idx_to_rm:\n",
    "        continue\n",
    "    \n",
    "    file_name += \".npy\"\n",
    "    src = join(old_train_path, file_name)\n",
    "    dst = join(new_train_path, file_name)\n",
    "\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29443\n"
     ]
    }
   ],
   "source": [
    "old_train_path = \"G:/Code/Dataset/archive/train/class_label\"\n",
    "new_train_path = \"G:/Code/Dataset/archive/train_reduced/class_label\"\n",
    "print(len(os.listdir(new_train_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_n = 3281\n",
    "\n",
    "omg_pred = np.load(r\"model_eval/omg_pred.npy\")\n",
    "omg_pred = omg_pred.reshape(32*batch_n, 15)\n",
    "\n",
    "omg_truth = np.load(r'model_eval/omg_truth.npy')\n",
    "omg_truth = omg_truth.reshape(32*batch_n,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = (omg_pred > 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predicted_labels.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'{predicted_labels[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13595337385533537\n",
      "0.21275462257441838\n",
      "0.34604389359370497\n",
      "0.15460501970834434\n",
      "0.19191144863930346\n"
     ]
    }
   ],
   "source": [
    "from eval import IoU_accuracy, Hamming_Loss, Recall, Precision, F1Measure\n",
    "\n",
    "print(IoU_accuracy(omg_truth,predicted_labels))\n",
    "print(Hamming_Loss(omg_truth,predicted_labels))\n",
    "print(Recall(omg_truth,predicted_labels))\n",
    "print(Precision(omg_truth,predicted_labels))\n",
    "print(F1Measure(omg_truth,predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(omg_truth , predicted_labels, output_dict=False, target_names=[label for label in label_map] ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
